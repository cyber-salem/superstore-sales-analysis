{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c179f458",
   "metadata": {},
   "source": [
    "- Cell 1: Importing Essential Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261ba03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e958c",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm loading the three core libraries I need for this sales analysis project. Pandas handles all my data manipulation, Seaborn creates polished visualizations, and Matplotlib gives me fine control over chart customization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90153ca4",
   "metadata": {},
   "source": [
    "- Cell 2: Loading Data and Engineering Time-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Superstore sales dataset.csv\")\n",
    "\n",
    "df[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"], dayfirst=True)\n",
    "df[\"Ship Date\"] = pd.to_datetime(df[\"Ship Date\"], dayfirst=True)  \n",
    "df[\"Delivery Time\"] = (df[\"Ship Date\"] - df[\"Order Date\"]).dt.days\n",
    "df[\"Order Months\"] = df[\"Order Date\"].dt.month \n",
    "df[\"Order Years\"] = df[\"Order Date\"].dt.year\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c28709f",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm loading the Superstore dataset and immediately creating features that will unlock time-based insights. I convert dates to datetime format (using dayfirst=True for DD/MM/YYYY), calculate delivery time in days, and extract months and years. These new columns will let me analyze seasonal patterns, delivery performance, and year-over-year trends throughout the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d70307",
   "metadata": {},
   "source": [
    "- Cell 3: Comprehensive Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f64c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df.columns)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a411c",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm performing a thorough data exploration before diving into analysis. df.info() reveals the dataset structure and data types, while I list all column names for quick reference. I check for missing values with isnull().sum() and use df.describe() to get statistical summaries of numerical columns (mean, standard deviation, min/max values). This complete assessment ensures I understand the data quality and distribution before building any visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcff0504",
   "metadata": {},
   "source": [
    "- Cell 4: Profit Analysis Across Years by Region and Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ff7522",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13 , 7))\n",
    "\n",
    "sns.scatterplot(x='Order Years' , y='Profit' , data=df ,style='Region' , hue='Discount' , palette='viridis' , alpha=0.7)\n",
    "\n",
    "plt.axhline(0 , color='red' , linestyle='--',  linewidth=1.4 , alpha=0.9)\n",
    "plt.title('Profit Analysis by Year and Region', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Profit ($)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.grid(True , color='LIghtblue' , linestyle=':' , alpha=0.8)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb0e70f",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm visualizing profit patterns over time using a scatter plot where each point represents an individual order. I'm using different point styles to distinguish between regions and a color gradient (viridis) to show discount levels. The red dashed line at y=0 helps me quickly identify profitable versus unprofitable transactions. This multi-dimensional view reveals how discounts impact profitability across different regions and years."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eb3422",
   "metadata": {},
   "source": [
    "- Cell 5: Annual Revenue Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yearly_sales = df.groupby('Order Years')['Sales'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "ax = sns.barplot(x='Order Years', y='Sales', data=yearly_sales, \n",
    "                 palette='viridis', edgecolor='black', linewidth=1.2) \n",
    "\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='${:,.0f}', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.title(\"Annual Revenue Growth\", fontsize=16, fontweight='bold', \n",
    "          pad=10, color=\"#49115d\")\n",
    "plt.xlabel('Year', fontsize=13, fontweight='bold', color='#34495e')\n",
    "plt.ylabel('Sales (Revenue)', fontsize=13, fontweight='bold', color='#34495e')\n",
    "\n",
    "\n",
    "plt.grid(axis='y', alpha=0.8, linestyle='--', linewidth=0.7)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42396e57",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm aggregating total sales by year to visualize revenue trends over time. I used groupby to sum all sales per year, then created a bar chart with value labels on top of each bar for precise readings. The grid is positioned behind the bars for clarity, and I chose a viridis color palette with black edges to make each year stand out. This gives a clear picture of year-over-year revenue growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe5e1b",
   "metadata": {},
   "source": [
    "- Cell 6: Delivery Time Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "avg_delivery = df['Delivery Time'].mean()\n",
    "print(f\"Average Delivery Time: {avg_delivery:.2f} days\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df['Delivery Time'], bins=15, kde=True, color='green')\n",
    "plt.title('Distribution of Delivery Time')\n",
    "plt.xlabel('Delivery Time (Days)', fontsize=11)\n",
    "plt.ylabel('Frequency', fontsize=11)\n",
    "plt.axvline(avg_delivery, color='red', linestyle='--', linewidth=2, label=f'Avg: {avg_delivery:.1f} days')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d3186d",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm analyzing delivery performance by calculating the average delivery time and visualizing its distribution. The histogram shows how delivery times are spread across orders, with a KDE curve revealing the overall pattern. I added a red vertical line marking the average delivery time directly on the chart, making it easy to see how most deliveries compare to the mean. This helps identify whether the business maintains consistent delivery times or if there are significant variations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684984af",
   "metadata": {},
   "source": [
    "Cell 7: Discount Impact on Profitability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.scatterplot(x='Discount', y='Profit', data=df, alpha=0.7, hue='Region', style= 'Category' , palette='icefire', s=52)\n",
    "\n",
    "plt.title('Impact of Discounts on Profitability', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Discount Rate', fontsize=12)\n",
    "plt.ylabel('Profit ($)', fontsize=12)\n",
    "\n",
    "plt.axhline(0, color='red', alpha=0.7, linestyle='--', linewidth=1.8, label='Break-even')\n",
    "\n",
    "plt.grid(True, alpha=0.7, linestyle=':')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8bae15",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm investigating how discount rates affect profitability across different regions and product categories. Each point represents an order, colored by region and shaped by category. The red dashed line at y=0 marks the break-even point, helping me quickly identify which discount levels lead to losses. This multi-dimensional analysis reveals whether certain regions or product categories are more sensitive to discounting strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8196d0",
   "metadata": {},
   "source": [
    "- Cell 8: Monthly Sales Trend with Peak Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb98905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "monthly_sales = df.groupby('Order Months')['Sales'].sum()\n",
    "\n",
    "\n",
    "max_month = monthly_sales.idxmax()\n",
    "max_sales = monthly_sales.max()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(monthly_sales.index, monthly_sales.values, \n",
    "         marker='o', markersize=8, linewidth=2, \n",
    "         color='steelblue', label='Monthly Sales')\n",
    "\n",
    "\n",
    "plt.plot(max_month, max_sales, \n",
    "         marker='*', markersize=20, \n",
    "         color='red', label='Highest Sales')\n",
    "\n",
    "\n",
    "plt.annotate(f'Peak Sales\\n${max_sales:,.0f}',\n",
    "             xy=(max_month, max_sales),\n",
    "             xytext=(max_month, max_sales + max_sales*0.1),\n",
    "             ha='center',\n",
    "             fontsize=12,\n",
    "             color='red',\n",
    "             fontweight='bold',\n",
    "             arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "\n",
    "\n",
    "plt.xlabel('Month', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Sales', fontsize=12, fontweight='bold')\n",
    "plt.title('Monthly Sales with Peak Highlight', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(True, alpha=0.3, linestyle='--')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f'Highest sales month: {max_month}')\n",
    "print(f'Sales value: ${max_sales:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b162eec",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm analyzing monthly sales patterns to identify seasonal trends and peak performance periods. I calculated total sales for each month and automatically identified the highest-performing month using idxmax(). The line chart clearly shows the sales trend throughout the year, with the peak month highlighted using a red star and an annotation showing the exact sales figure. This reveals important seasonal patterns that can inform inventory planning and marketing strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180101c9",
   "metadata": {},
   "source": [
    "- Cell 9: Top 10 Best-Selling Sub-Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd66e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np  \n",
    "\n",
    "top_subcategories = df.groupby('Sub-Category')['Sales'].sum().nlargest(10).sort_values()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.9, len(top_subcategories)))\n",
    "\n",
    "\n",
    "bars = plt.barh(top_subcategories.index, top_subcategories.values, color=colors, edgecolor='navy', linewidth=1.5)\n",
    "\n",
    "\n",
    "for i, (value, bar) in enumerate(zip(top_subcategories.values, bars)):\n",
    "    plt.text(value + value*0.02,  \n",
    "             i,                    \n",
    "             f'${value:,.0f}',     \n",
    "             va='center',          \n",
    "             fontsize=11,\n",
    "             fontweight='bold',\n",
    "             color='darkblue')\n",
    "\n",
    "# ÿ™ÿ≠ÿ≥ŸäŸÜÿßÿ™ ÿßŸÑÿ±ÿ≥ŸÖ\n",
    "plt.xlabel('Sales ($)', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Sub-Category', fontsize=13, fontweight='bold')\n",
    "plt.title('Top 10 Sub-Categories by Sales üèÜ', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(axis='x', alpha=0.3, linestyle='--')\n",
    "\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Top 10 Sub-Categories:\")\n",
    "print(\"=\" * 50)\n",
    "for i, (cat, sales) in enumerate(top_subcategories.sort_values(ascending=False).items(), 1):\n",
    "    print(f\"{i}. {cat:.<30} ${sales:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16412f",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm identifying the top 10 best-selling product sub-categories to understand which products drive the most revenue. I used a horizontal bar chart with a color gradient (from light to dark blue) to visually rank the categories, making it easy to spot the top performers at a glance. The values are displayed directly on the bars for precise readings, and I've removed the top and right spines for a cleaner, more modern look. The printed summary table provides exact rankings and sales figures for quick reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116b0a4",
   "metadata": {},
   "source": [
    "- Cell 10 : Regional Sales Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf4d525",
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_sales = df.groupby('Region')['Sales'].sum().sort_values(ascending=False)\n",
    "regional_sales_df = regional_sales.reset_index() \n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "az = sns.barplot(x='Region', y='Sales', data=regional_sales_df, palette='viridis', edgecolor='black', linewidth=1.2)\n",
    "\n",
    "for container in az.containers:  \n",
    "    az.bar_label(container, fmt='${:,.0f}', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.title(\"Regional Sales Performance\", fontsize=17, fontweight='bold', pad=12, color=\"#34211B\")    \n",
    "plt.ylabel(\"Total Sales ($)\", fontsize=12, fontweight='bold') \n",
    "plt.xlabel(\"Region\", fontsize=12, fontweight='bold')\n",
    "\n",
    "az.set_axisbelow(True) \n",
    "plt.grid(axis='y', alpha=0.8, linestyle='--', linewidth=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa8711",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm analyzing total sales performance across different regions to identify which geographic areas generate the most revenue. I aggregated sales by region using groupby and sorted them in descending order to highlight top performers. The bar chart includes exact dollar values on top of each bar, making it easy to compare regional contributions. This insight helps understand where the business is strongest and which regions might need more attention or resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0435094",
   "metadata": {},
   "source": [
    "- Cell 11: Exporting Cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9771e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Cleaned_Superstore_Final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e7b5c",
   "metadata": {},
   "source": [
    "What I'm doing here: I'm saving the cleaned and enhanced dataset to a new CSV file. This preserves all the feature engineering work I did earlier (Delivery Time, Order Months, Order Years) so I can reuse this processed data in future analyses without repeating the cleaning steps. Using index=False ensures the DataFrame's row numbers aren't saved as an extra column in the CSV file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
